{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oualidall/oualid/blob/oualidallouch/drone_yolov8_json_pipeline(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92eb9431",
      "metadata": {
        "id": "92eb9431"
      },
      "source": [
        "# ğŸ¯ Drone Video to YOLOv8 JSON Annotations\n",
        "This notebook extracts frames from drone videos, runs YOLOv8 inference, and generates JSON annotation files for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ea4a4940",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea4a4940",
        "outputId": "b7bfa6cf-8273-41a5-ba04-01624722d4e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.170-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.170-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.170 ultralytics-thop-2.0.14\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ğŸ“¦ Install dependencies\n",
        "!pip install ultralytics opencv-python\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3028417a"
      },
      "source": [
        "# Task\n",
        "Run a full pipeline in Colab to process two drone videos: extract frames, run YOLOv8 inference on each frame using a pre-trained model (\"yolov8s.pt\" or \"best.pt\"), generate a JSON annotation file for each image with bounding box coordinates and confidence scores, save all JSON files in a folder, and prepare the folder for export to a GitHub repository."
      ],
      "id": "3028417a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f98965d"
      },
      "source": [
        "## Upload videos\n",
        "\n",
        "### Subtask:\n",
        "Provide code to upload drone video files.\n"
      ],
      "id": "0f98965d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf3d5d16"
      },
      "source": [
        "**Reasoning**:\n",
        "Use the google.colab.files.upload() function to upload the video files.\n",
        "\n"
      ],
      "id": "bf3d5d16"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9df88829",
        "outputId": "1d8a06fb-3cdf-4809-a602-9a3ba0baa7f3"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "id": "9df88829",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b12ee5fe-892e-4180-ae0e-28a2d2cfd9d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b12ee5fe-892e-4180-ae0e-28a2d2cfd9d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video1.mp4.mp4 to video1.mp4.mp4\n",
            "Saving video2.mp4.mp4 to video2.mp4.mp4\n",
            "User uploaded file \"video1.mp4.mp4\" with length 27030484 bytes\n",
            "User uploaded file \"video2.mp4.mp4\" with length 35001979 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c116f37d"
      },
      "source": [
        "## Extract frames\n",
        "\n",
        "### Subtask:\n",
        "Extract frames from the uploaded videos and save them as images.\n"
      ],
      "id": "c116f37d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "783fd1ff"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the uploaded videos, extract frames, and save them as images in dedicated directories.\n",
        "\n"
      ],
      "id": "783fd1ff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "2532498d",
        "outputId": "12b23e6f-3466-469c-874e-ecc67c3439d3"
      },
      "source": [
        "for video_filename in uploaded.keys():\n",
        "    # Create a directory for frames\n",
        "    frame_dir = os.path.splitext(video_filename)[0]\n",
        "    os.makedirs(frame_dir, exist_ok=True)\n",
        "    print(f\"Created directory: {frame_dir}\")\n",
        "\n",
        "    # Initialize video capture\n",
        "    cap = cv2.VideoCapture(video_filename)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_filename}\")\n",
        "        continue\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "\n",
        "        if success:\n",
        "            # Construct output filename\n",
        "            output_filename = os.path.join(frame_dir, f\"frame_{frame_count:04d}.jpg\")\n",
        "            # Save the frame\n",
        "            cv2.imwrite(output_filename, frame)\n",
        "            frame_count += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {frame_count} frames from {video_filename}\")\n"
      ],
      "id": "2532498d",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: video1.mp4\n",
            "Extracted 4412 frames from video1.mp4.mp4\n",
            "Created directory: video2.mp4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1643565029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutput_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"frame_{frame_count:04d}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Save the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mframe_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db1eae30"
      },
      "source": [
        "## Run inference and generate json\n",
        "\n",
        "### Subtask:\n",
        "Iterate through the extracted frames, run YOLOv8 inference on each frame, and generate a JSON annotation file for each image with bounding box coordinates and confidence scores.\n"
      ],
      "id": "db1eae30"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cb04484"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through the extracted frames, run YOLOv8 inference on each frame, generate a JSON annotation file for each image with bounding box coordinates and confidence scores, and save them in an 'annotations' directory.\n",
        "\n"
      ],
      "id": "9cb04484"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b442a222",
        "outputId": "3c92621e-0dcb-4e6f-8a82-c910dfde15a8"
      },
      "source": [
        "# ğŸï¸ Extract frames from both videos\n",
        "# Assuming the uploaded files are in the current directory\n",
        "video_files = list(uploaded.keys()) # Use the keys from the uploaded dictionary\n",
        "output_dir = Path('frames_dataset')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "frame_count = 0\n",
        "frame_interval = 30  # Extract every 30th frame\n",
        "\n",
        "for video in video_files:\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    success, frame = cap.read()\n",
        "    frame_idx = 0\n",
        "    while success:\n",
        "        if frame_idx % frame_interval == 0:\n",
        "            frame_path = output_dir / f\"{Path(video).stem}_frame{frame_count:04d}.jpg\"\n",
        "            cv2.imwrite(str(frame_path), frame)\n",
        "            frame_count += 1\n",
        "        success, frame = cap.read()\n",
        "        frame_idx += 1\n",
        "    cap.release()\n",
        "\n",
        "print(f\"âœ… Extracted {frame_count} frames to {output_dir}\")"
      ],
      "id": "b442a222",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extracted 339 frames to frames_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ac59db",
        "outputId": "edcc56e7-c309-4441-882f-34be8b61a9e7"
      },
      "source": [
        "# Load a pre-trained YOLOv8s model\n",
        "model = YOLO('yolov8s.pt')\n",
        "print(\"YOLOv8 model loaded successfully.\")"
      ],
      "id": "58ac59db",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 121MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fefd1933",
        "outputId": "b0fcc230-2e10-4e2a-f479-601e1168f594"
      },
      "source": [
        "# ğŸƒâ€â™€ï¸ Run inference and generate JSON annotations\n",
        "annotations_dir = Path('annotations')\n",
        "annotations_dir.mkdir(exist_ok=True)\n",
        "\n",
        "frame_paths = list(output_dir.glob(\"*.jpg\")) # Use the output_dir from frame extraction\n",
        "print(f\"Found {len(frame_paths)} frames for inference.\")\n",
        "\n",
        "for frame_path in frame_paths:\n",
        "    results = model(str(frame_path))  # Run inference\n",
        "\n",
        "    # Process results and generate JSON\n",
        "    annotation_data = {\n",
        "        \"image_filename\": frame_path.name,\n",
        "        \"image_dimensions\": {\n",
        "            \"width\": int(results[0].orig_shape[1]),\n",
        "            \"height\": int(results[0].orig_shape[0])\n",
        "        },\n",
        "        \"objects\": []\n",
        "    }\n",
        "\n",
        "    for r in results:\n",
        "        if r.boxes is not None:\n",
        "            for box in r.boxes:\n",
        "                x_min, y_min, x_max, y_max = [float(i) for i in box.xyxy[0]]\n",
        "                confidence = float(box.conf[0])\n",
        "                class_id = int(box.cls[0])\n",
        "                obj_name = model.names[class_id]\n",
        "\n",
        "                annotation_data[\"objects\"].append({\n",
        "                    \"contour\": {\"x\": x_min, \"y\": y_min, \"w\": x_max - x_min, \"h\": y_max - y_min},\n",
        "                    \"obj_name\": obj_name,\n",
        "                    \"name_accuracy\": confidence\n",
        "                })\n",
        "\n",
        "    # Save JSON\n",
        "    json_filename = annotations_dir / f\"{frame_path.stem}.json\"\n",
        "    with open(json_filename, 'w') as f:\n",
        "        json.dump(annotation_data, f, indent=2)\n",
        "\n",
        "print(f\"âœ… Generated JSON annotations for {len(frame_paths)} frames in {annotations_dir}\")"
      ],
      "id": "fefd1933",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 339 frames for inference.\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0110.jpg: 384x640 2 cars, 641.9ms\n",
            "Speed: 25.1ms preprocess, 641.9ms inference, 42.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0086.jpg: 384x640 1 person, 2 cars, 2 motorcycles, 406.5ms\n",
            "Speed: 2.8ms preprocess, 406.5ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0280.jpg: 384x640 2 cars, 374.0ms\n",
            "Speed: 3.0ms preprocess, 374.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0030.jpg: 384x640 (no detections), 394.3ms\n",
            "Speed: 3.3ms preprocess, 394.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0264.jpg: 384x640 4 persons, 379.6ms\n",
            "Speed: 3.0ms preprocess, 379.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0207.jpg: 384x640 (no detections), 393.7ms\n",
            "Speed: 3.9ms preprocess, 393.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0317.jpg: 384x640 1 person, 5 cars, 408.7ms\n",
            "Speed: 2.7ms preprocess, 408.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0114.jpg: 384x640 (no detections), 394.3ms\n",
            "Speed: 2.7ms preprocess, 394.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0006.jpg: 384x640 (no detections), 409.2ms\n",
            "Speed: 2.6ms preprocess, 409.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0091.jpg: 384x640 1 car, 389.0ms\n",
            "Speed: 2.7ms preprocess, 389.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0122.jpg: 384x640 1 car, 383.4ms\n",
            "Speed: 2.9ms preprocess, 383.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0050.jpg: 384x640 1 car, 401.9ms\n",
            "Speed: 2.6ms preprocess, 401.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0005.jpg: 384x640 (no detections), 376.4ms\n",
            "Speed: 2.9ms preprocess, 376.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0259.jpg: 384x640 3 persons, 426.4ms\n",
            "Speed: 4.1ms preprocess, 426.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0013.jpg: 384x640 (no detections), 391.7ms\n",
            "Speed: 4.4ms preprocess, 391.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0156.jpg: 384x640 1 person, 3 cars, 582.4ms\n",
            "Speed: 3.8ms preprocess, 582.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0225.jpg: 384x640 (no detections), 594.9ms\n",
            "Speed: 4.1ms preprocess, 594.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0061.jpg: 384x640 (no detections), 589.2ms\n",
            "Speed: 3.9ms preprocess, 589.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0048.jpg: 384x640 (no detections), 608.2ms\n",
            "Speed: 7.8ms preprocess, 608.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0255.jpg: 384x640 2 persons, 1 traffic light, 1 bird, 600.4ms\n",
            "Speed: 4.2ms preprocess, 600.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0273.jpg: 384x640 4 persons, 1 airplane, 648.1ms\n",
            "Speed: 7.7ms preprocess, 648.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0016.jpg: 384x640 (no detections), 387.8ms\n",
            "Speed: 4.6ms preprocess, 387.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0319.jpg: 384x640 6 cars, 1 truck, 391.6ms\n",
            "Speed: 2.8ms preprocess, 391.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0058.jpg: 384x640 (no detections), 397.4ms\n",
            "Speed: 2.7ms preprocess, 397.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0253.jpg: 384x640 4 persons, 388.9ms\n",
            "Speed: 3.2ms preprocess, 388.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0020.jpg: 384x640 (no detections), 382.4ms\n",
            "Speed: 2.9ms preprocess, 382.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0092.jpg: 384x640 (no detections), 394.9ms\n",
            "Speed: 2.7ms preprocess, 394.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0210.jpg: 384x640 (no detections), 394.9ms\n",
            "Speed: 3.6ms preprocess, 394.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0026.jpg: 384x640 (no detections), 403.5ms\n",
            "Speed: 4.2ms preprocess, 403.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0216.jpg: 384x640 1 boat, 377.9ms\n",
            "Speed: 2.7ms preprocess, 377.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0246.jpg: 384x640 1 person, 1 traffic light, 380.4ms\n",
            "Speed: 3.8ms preprocess, 380.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0237.jpg: 384x640 (no detections), 408.3ms\n",
            "Speed: 4.0ms preprocess, 408.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0288.jpg: 384x640 (no detections), 380.7ms\n",
            "Speed: 2.6ms preprocess, 380.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0272.jpg: 384x640 2 persons, 402.7ms\n",
            "Speed: 2.9ms preprocess, 402.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0129.jpg: 384x640 (no detections), 394.3ms\n",
            "Speed: 2.6ms preprocess, 394.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0177.jpg: 384x640 3 persons, 381.3ms\n",
            "Speed: 3.9ms preprocess, 381.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0087.jpg: 384x640 1 person, 2 cars, 399.4ms\n",
            "Speed: 2.8ms preprocess, 399.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0081.jpg: 384x640 1 person, 1 car, 388.4ms\n",
            "Speed: 2.9ms preprocess, 388.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0094.jpg: 384x640 (no detections), 392.1ms\n",
            "Speed: 4.2ms preprocess, 392.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0145.jpg: 384x640 (no detections), 385.2ms\n",
            "Speed: 3.7ms preprocess, 385.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0149.jpg: 384x640 2 persons, 2 cars, 1 cell phone, 388.7ms\n",
            "Speed: 4.8ms preprocess, 388.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0017.jpg: 384x640 (no detections), 413.6ms\n",
            "Speed: 4.0ms preprocess, 413.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0178.jpg: 384x640 1 person, 1 car, 384.2ms\n",
            "Speed: 3.5ms preprocess, 384.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0071.jpg: 384x640 1 person, 403.2ms\n",
            "Speed: 3.5ms preprocess, 403.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0201.jpg: 384x640 (no detections), 398.8ms\n",
            "Speed: 3.8ms preprocess, 398.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0276.jpg: 384x640 2 persons, 532.6ms\n",
            "Speed: 2.9ms preprocess, 532.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0115.jpg: 384x640 (no detections), 620.2ms\n",
            "Speed: 3.6ms preprocess, 620.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0271.jpg: 384x640 3 persons, 606.9ms\n",
            "Speed: 3.8ms preprocess, 606.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0023.jpg: 384x640 (no detections), 603.9ms\n",
            "Speed: 7.3ms preprocess, 603.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0298.jpg: 384x640 (no detections), 618.7ms\n",
            "Speed: 4.4ms preprocess, 618.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0151.jpg: 384x640 2 persons, 1 car, 677.3ms\n",
            "Speed: 8.2ms preprocess, 677.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0029.jpg: 384x640 (no detections), 404.4ms\n",
            "Speed: 8.0ms preprocess, 404.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0176.jpg: 384x640 2 persons, 1 car, 380.4ms\n",
            "Speed: 3.8ms preprocess, 380.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0109.jpg: 384x640 (no detections), 400.2ms\n",
            "Speed: 3.9ms preprocess, 400.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0203.jpg: 384x640 (no detections), 378.2ms\n",
            "Speed: 2.7ms preprocess, 378.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0172.jpg: 384x640 1 car, 382.9ms\n",
            "Speed: 2.7ms preprocess, 382.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0227.jpg: 384x640 (no detections), 395.8ms\n",
            "Speed: 4.1ms preprocess, 395.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0038.jpg: 384x640 1 bench, 378.0ms\n",
            "Speed: 4.2ms preprocess, 378.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0285.jpg: 384x640 1 oven, 385.3ms\n",
            "Speed: 4.3ms preprocess, 385.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0282.jpg: 384x640 1 car, 388.5ms\n",
            "Speed: 9.7ms preprocess, 388.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0034.jpg: 384x640 (no detections), 380.8ms\n",
            "Speed: 3.5ms preprocess, 380.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0097.jpg: 384x640 1 traffic light, 412.5ms\n",
            "Speed: 4.1ms preprocess, 412.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0078.jpg: 384x640 1 person, 406.8ms\n",
            "Speed: 3.5ms preprocess, 406.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0217.jpg: 384x640 (no detections), 381.4ms\n",
            "Speed: 3.5ms preprocess, 381.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0290.jpg: 384x640 (no detections), 392.2ms\n",
            "Speed: 7.0ms preprocess, 392.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0254.jpg: 384x640 4 persons, 381.9ms\n",
            "Speed: 2.6ms preprocess, 381.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0153.jpg: 384x640 2 persons, 2 cars, 405.6ms\n",
            "Speed: 3.0ms preprocess, 405.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0279.jpg: 384x640 2 persons, 1 car, 392.5ms\n",
            "Speed: 4.2ms preprocess, 392.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0211.jpg: 384x640 (no detections), 380.2ms\n",
            "Speed: 2.9ms preprocess, 380.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0214.jpg: 384x640 (no detections), 392.6ms\n",
            "Speed: 2.5ms preprocess, 392.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0027.jpg: 384x640 (no detections), 379.5ms\n",
            "Speed: 3.3ms preprocess, 379.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0277.jpg: 384x640 2 persons, 395.1ms\n",
            "Speed: 3.2ms preprocess, 395.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0084.jpg: 384x640 2 cars, 378.6ms\n",
            "Speed: 4.6ms preprocess, 378.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0000.jpg: 384x640 (no detections), 381.1ms\n",
            "Speed: 3.1ms preprocess, 381.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0105.jpg: 384x640 1 car, 398.3ms\n",
            "Speed: 3.9ms preprocess, 398.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0074.jpg: 384x640 1 person, 465.4ms\n",
            "Speed: 3.0ms preprocess, 465.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0297.jpg: 384x640 (no detections), 618.5ms\n",
            "Speed: 4.0ms preprocess, 618.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0165.jpg: 384x640 1 person, 3 cars, 592.9ms\n",
            "Speed: 4.0ms preprocess, 592.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0278.jpg: 384x640 2 persons, 608.0ms\n",
            "Speed: 3.9ms preprocess, 608.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0284.jpg: 384x640 (no detections), 605.2ms\n",
            "Speed: 3.7ms preprocess, 605.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0077.jpg: 384x640 (no detections), 642.0ms\n",
            "Speed: 4.0ms preprocess, 642.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0258.jpg: 384x640 3 persons, 1 car, 520.2ms\n",
            "Speed: 5.2ms preprocess, 520.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0318.jpg: 384x640 3 cars, 379.1ms\n",
            "Speed: 4.0ms preprocess, 379.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0095.jpg: 384x640 (no detections), 378.3ms\n",
            "Speed: 3.8ms preprocess, 378.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0212.jpg: 384x640 (no detections), 399.8ms\n",
            "Speed: 4.0ms preprocess, 399.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0073.jpg: 384x640 1 person, 378.0ms\n",
            "Speed: 2.6ms preprocess, 378.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0197.jpg: 384x640 (no detections), 398.9ms\n",
            "Speed: 3.0ms preprocess, 398.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0198.jpg: 384x640 (no detections), 385.6ms\n",
            "Speed: 3.6ms preprocess, 385.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0167.jpg: 384x640 1 car, 373.4ms\n",
            "Speed: 2.6ms preprocess, 373.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0150.jpg: 384x640 2 persons, 2 cars, 4 cell phones, 388.7ms\n",
            "Speed: 3.7ms preprocess, 388.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0128.jpg: 384x640 (no detections), 379.9ms\n",
            "Speed: 2.7ms preprocess, 379.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0002.jpg: 384x640 1 car, 385.0ms\n",
            "Speed: 3.9ms preprocess, 385.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0249.jpg: 384x640 1 car, 1 traffic light, 399.2ms\n",
            "Speed: 3.7ms preprocess, 399.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0028.jpg: 384x640 1 bench, 377.8ms\n",
            "Speed: 4.4ms preprocess, 377.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0126.jpg: 384x640 (no detections), 401.6ms\n",
            "Speed: 3.8ms preprocess, 401.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0070.jpg: 384x640 1 person, 376.0ms\n",
            "Speed: 2.7ms preprocess, 376.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0232.jpg: 384x640 (no detections), 381.1ms\n",
            "Speed: 3.8ms preprocess, 381.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0031.jpg: 384x640 (no detections), 400.0ms\n",
            "Speed: 3.0ms preprocess, 400.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0148.jpg: 384x640 2 persons, 2 cars, 1 toilet, 371.2ms\n",
            "Speed: 3.5ms preprocess, 371.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0308.jpg: 384x640 2 persons, 1 car, 399.7ms\n",
            "Speed: 2.9ms preprocess, 399.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0220.jpg: 384x640 (no detections), 379.6ms\n",
            "Speed: 2.6ms preprocess, 379.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0066.jpg: 384x640 1 person, 393.0ms\n",
            "Speed: 3.9ms preprocess, 393.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0218.jpg: 384x640 (no detections), 398.6ms\n",
            "Speed: 2.6ms preprocess, 398.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0057.jpg: 384x640 (no detections), 372.2ms\n",
            "Speed: 3.9ms preprocess, 372.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0228.jpg: 384x640 (no detections), 396.5ms\n",
            "Speed: 4.0ms preprocess, 396.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0269.jpg: 384x640 2 persons, 377.7ms\n",
            "Speed: 3.6ms preprocess, 377.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0079.jpg: 384x640 1 person, 559.3ms\n",
            "Speed: 4.1ms preprocess, 559.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0215.jpg: 384x640 (no detections), 601.0ms\n",
            "Speed: 4.4ms preprocess, 601.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0329.jpg: 384x640 2 persons, 4 cars, 2 handbags, 1 bottle, 1 chair, 608.6ms\n",
            "Speed: 4.4ms preprocess, 608.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0011.jpg: 384x640 (no detections), 613.5ms\n",
            "Speed: 7.0ms preprocess, 613.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0193.jpg: 384x640 (no detections), 616.6ms\n",
            "Speed: 3.6ms preprocess, 616.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0182.jpg: 384x640 1 train, 1 cow, 701.1ms\n",
            "Speed: 7.8ms preprocess, 701.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0293.jpg: 384x640 (no detections), 404.9ms\n",
            "Speed: 3.9ms preprocess, 404.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0054.jpg: 384x640 1 car, 1 airplane, 380.6ms\n",
            "Speed: 3.8ms preprocess, 380.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0130.jpg: 384x640 (no detections), 399.8ms\n",
            "Speed: 2.9ms preprocess, 399.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0236.jpg: 384x640 (no detections), 385.0ms\n",
            "Speed: 2.5ms preprocess, 385.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0022.jpg: 384x640 (no detections), 387.5ms\n",
            "Speed: 3.9ms preprocess, 387.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0306.jpg: 384x640 1 person, 1 car, 398.2ms\n",
            "Speed: 3.5ms preprocess, 398.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0067.jpg: 384x640 1 person, 383.1ms\n",
            "Speed: 3.7ms preprocess, 383.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0219.jpg: 384x640 (no detections), 408.8ms\n",
            "Speed: 4.2ms preprocess, 408.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0080.jpg: 384x640 1 person, 2 cars, 1 truck, 382.2ms\n",
            "Speed: 2.6ms preprocess, 382.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0139.jpg: 384x640 1 frisbee, 376.1ms\n",
            "Speed: 2.8ms preprocess, 376.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0045.jpg: 384x640 (no detections), 418.6ms\n",
            "Speed: 3.9ms preprocess, 418.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0202.jpg: 384x640 (no detections), 379.8ms\n",
            "Speed: 2.9ms preprocess, 379.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0322.jpg: 384x640 2 persons, 5 cars, 1 truck, 392.7ms\n",
            "Speed: 3.5ms preprocess, 392.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0003.jpg: 384x640 1 car, 386.1ms\n",
            "Speed: 3.7ms preprocess, 386.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0142.jpg: 384x640 (no detections), 378.0ms\n",
            "Speed: 3.4ms preprocess, 378.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0235.jpg: 384x640 (no detections), 406.3ms\n",
            "Speed: 3.6ms preprocess, 406.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0107.jpg: 384x640 1 car, 383.7ms\n",
            "Speed: 2.8ms preprocess, 383.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0137.jpg: 384x640 1 person, 384.9ms\n",
            "Speed: 2.7ms preprocess, 384.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0025.jpg: 384x640 (no detections), 406.8ms\n",
            "Speed: 3.7ms preprocess, 406.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0113.jpg: 384x640 1 car, 381.3ms\n",
            "Speed: 2.7ms preprocess, 381.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0021.jpg: 384x640 (no detections), 394.0ms\n",
            "Speed: 2.9ms preprocess, 394.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0123.jpg: 384x640 (no detections), 395.9ms\n",
            "Speed: 5.8ms preprocess, 395.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0032.jpg: 384x640 (no detections), 377.8ms\n",
            "Speed: 4.6ms preprocess, 377.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0127.jpg: 384x640 (no detections), 442.4ms\n",
            "Speed: 4.9ms preprocess, 442.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0096.jpg: 384x640 1 car, 507.4ms\n",
            "Speed: 4.1ms preprocess, 507.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0155.jpg: 384x640 1 person, 5 cars, 623.7ms\n",
            "Speed: 6.2ms preprocess, 623.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0076.jpg: 384x640 (no detections), 626.0ms\n",
            "Speed: 3.7ms preprocess, 626.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0333.jpg: 384x640 3 persons, 621.2ms\n",
            "Speed: 5.8ms preprocess, 621.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0263.jpg: 384x640 2 persons, 1 car, 1 traffic light, 619.7ms\n",
            "Speed: 3.6ms preprocess, 619.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0088.jpg: 384x640 2 persons, 710.0ms\n",
            "Speed: 4.6ms preprocess, 710.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0174.jpg: 384x640 1 car, 400.1ms\n",
            "Speed: 3.5ms preprocess, 400.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0206.jpg: 384x640 (no detections), 397.1ms\n",
            "Speed: 3.8ms preprocess, 397.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0161.jpg: 384x640 1 person, 4 cars, 383.5ms\n",
            "Speed: 3.5ms preprocess, 383.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0090.jpg: 384x640 1 person, 2 cars, 403.8ms\n",
            "Speed: 4.1ms preprocess, 403.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0041.jpg: 384x640 (no detections), 397.6ms\n",
            "Speed: 4.1ms preprocess, 397.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0093.jpg: 384x640 (no detections), 403.1ms\n",
            "Speed: 2.7ms preprocess, 403.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0102.jpg: 384x640 1 car, 1 boat, 384.8ms\n",
            "Speed: 4.8ms preprocess, 384.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0158.jpg: 384x640 3 cars, 387.1ms\n",
            "Speed: 3.0ms preprocess, 387.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0170.jpg: 384x640 3 cars, 390.8ms\n",
            "Speed: 2.9ms preprocess, 390.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0243.jpg: 384x640 3 cars, 384.7ms\n",
            "Speed: 6.4ms preprocess, 384.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0205.jpg: 384x640 (no detections), 401.3ms\n",
            "Speed: 3.7ms preprocess, 401.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0221.jpg: 384x640 (no detections), 373.5ms\n",
            "Speed: 2.5ms preprocess, 373.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0001.jpg: 384x640 (no detections), 391.1ms\n",
            "Speed: 3.5ms preprocess, 391.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0135.jpg: 384x640 (no detections), 401.8ms\n",
            "Speed: 3.0ms preprocess, 401.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0336.jpg: 384x640 2 persons, 2 cars, 392.6ms\n",
            "Speed: 3.7ms preprocess, 392.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0072.jpg: 384x640 1 person, 398.1ms\n",
            "Speed: 4.5ms preprocess, 398.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0098.jpg: 384x640 1 traffic light, 381.1ms\n",
            "Speed: 5.3ms preprocess, 381.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0291.jpg: 384x640 1 train, 378.5ms\n",
            "Speed: 3.5ms preprocess, 378.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0303.jpg: 384x640 (no detections), 396.0ms\n",
            "Speed: 3.2ms preprocess, 396.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0019.jpg: 384x640 1 car, 386.8ms\n",
            "Speed: 2.7ms preprocess, 386.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0143.jpg: 384x640 (no detections), 398.0ms\n",
            "Speed: 3.6ms preprocess, 398.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0062.jpg: 384x640 (no detections), 385.2ms\n",
            "Speed: 3.8ms preprocess, 385.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0295.jpg: 384x640 (no detections), 384.2ms\n",
            "Speed: 2.7ms preprocess, 384.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0304.jpg: 384x640 (no detections), 407.9ms\n",
            "Speed: 5.5ms preprocess, 407.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0222.jpg: 384x640 (no detections), 483.2ms\n",
            "Speed: 2.6ms preprocess, 483.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0286.jpg: 384x640 (no detections), 620.0ms\n",
            "Speed: 4.2ms preprocess, 620.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0337.jpg: 384x640 2 persons, 1 car, 588.1ms\n",
            "Speed: 3.8ms preprocess, 588.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0229.jpg: 384x640 (no detections), 626.0ms\n",
            "Speed: 7.8ms preprocess, 626.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0252.jpg: 384x640 4 persons, 607.6ms\n",
            "Speed: 4.7ms preprocess, 607.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0245.jpg: 384x640 1 person, 1 car, 661.7ms\n",
            "Speed: 8.0ms preprocess, 661.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0037.jpg: 384x640 (no detections), 443.6ms\n",
            "Speed: 4.7ms preprocess, 443.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0305.jpg: 384x640 (no detections), 378.5ms\n",
            "Speed: 3.8ms preprocess, 378.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0124.jpg: 384x640 (no detections), 403.1ms\n",
            "Speed: 4.8ms preprocess, 403.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0064.jpg: 384x640 (no detections), 398.1ms\n",
            "Speed: 4.3ms preprocess, 398.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0040.jpg: 384x640 (no detections), 378.2ms\n",
            "Speed: 4.0ms preprocess, 378.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0069.jpg: 384x640 1 person, 396.7ms\n",
            "Speed: 4.8ms preprocess, 396.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0311.jpg: 384x640 2 persons, 2 cars, 2 buss, 381.5ms\n",
            "Speed: 4.0ms preprocess, 381.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0328.jpg: 384x640 3 persons, 1 bicycle, 4 cars, 1 handbag, 389.0ms\n",
            "Speed: 3.9ms preprocess, 389.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0223.jpg: 384x640 (no detections), 419.4ms\n",
            "Speed: 3.9ms preprocess, 419.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0055.jpg: 384x640 (no detections), 387.8ms\n",
            "Speed: 3.5ms preprocess, 387.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0169.jpg: 384x640 2 cars, 394.0ms\n",
            "Speed: 3.7ms preprocess, 394.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0112.jpg: 384x640 1 car, 397.7ms\n",
            "Speed: 4.9ms preprocess, 397.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0194.jpg: 384x640 (no detections), 373.2ms\n",
            "Speed: 3.7ms preprocess, 373.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0331.jpg: 384x640 2 persons, 3 cars, 401.8ms\n",
            "Speed: 4.1ms preprocess, 401.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0185.jpg: 384x640 (no detections), 396.2ms\n",
            "Speed: 4.1ms preprocess, 396.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0313.jpg: 384x640 4 cars, 1 bus, 389.3ms\n",
            "Speed: 3.6ms preprocess, 389.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0200.jpg: 384x640 (no detections), 398.6ms\n",
            "Speed: 2.7ms preprocess, 398.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0036.jpg: 384x640 (no detections), 380.9ms\n",
            "Speed: 2.6ms preprocess, 380.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0039.jpg: 384x640 1 bench, 395.1ms\n",
            "Speed: 3.9ms preprocess, 395.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0133.jpg: 384x640 1 bird, 373.1ms\n",
            "Speed: 3.2ms preprocess, 373.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0065.jpg: 384x640 1 person, 384.9ms\n",
            "Speed: 3.8ms preprocess, 384.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0035.jpg: 384x640 (no detections), 397.7ms\n",
            "Speed: 4.2ms preprocess, 397.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0325.jpg: 384x640 2 persons, 4 cars, 379.9ms\n",
            "Speed: 3.7ms preprocess, 379.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0116.jpg: 384x640 (no detections), 413.9ms\n",
            "Speed: 3.9ms preprocess, 413.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0044.jpg: 384x640 (no detections), 475.2ms\n",
            "Speed: 3.1ms preprocess, 475.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0060.jpg: 384x640 (no detections), 614.3ms\n",
            "Speed: 3.7ms preprocess, 614.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0260.jpg: 384x640 2 persons, 614.1ms\n",
            "Speed: 5.8ms preprocess, 614.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0008.jpg: 384x640 (no detections), 607.8ms\n",
            "Speed: 4.4ms preprocess, 607.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0289.jpg: 384x640 (no detections), 602.5ms\n",
            "Speed: 7.0ms preprocess, 602.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0190.jpg: 384x640 (no detections), 670.5ms\n",
            "Speed: 3.7ms preprocess, 670.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0265.jpg: 384x640 3 persons, 1 airplane, 441.6ms\n",
            "Speed: 5.3ms preprocess, 441.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0160.jpg: 384x640 1 car, 394.1ms\n",
            "Speed: 4.1ms preprocess, 394.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0226.jpg: 384x640 (no detections), 384.5ms\n",
            "Speed: 3.9ms preprocess, 384.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0103.jpg: 384x640 (no detections), 398.3ms\n",
            "Speed: 3.0ms preprocess, 398.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0242.jpg: 384x640 2 cars, 376.7ms\n",
            "Speed: 3.9ms preprocess, 376.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0015.jpg: 384x640 (no detections), 391.4ms\n",
            "Speed: 3.0ms preprocess, 391.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0266.jpg: 384x640 3 persons, 400.8ms\n",
            "Speed: 2.7ms preprocess, 400.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0119.jpg: 384x640 2 persons, 1 bicycle, 1 motorcycle, 379.8ms\n",
            "Speed: 5.3ms preprocess, 379.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0099.jpg: 384x640 (no detections), 419.7ms\n",
            "Speed: 5.1ms preprocess, 419.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0104.jpg: 384x640 (no detections), 374.4ms\n",
            "Speed: 3.8ms preprocess, 374.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0140.jpg: 384x640 (no detections), 384.4ms\n",
            "Speed: 4.2ms preprocess, 384.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0187.jpg: 384x640 (no detections), 408.2ms\n",
            "Speed: 4.5ms preprocess, 408.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0262.jpg: 384x640 2 persons, 383.3ms\n",
            "Speed: 3.9ms preprocess, 383.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0299.jpg: 384x640 1 potted plant, 383.6ms\n",
            "Speed: 3.9ms preprocess, 383.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0335.jpg: 384x640 3 persons, 1 car, 399.1ms\n",
            "Speed: 4.1ms preprocess, 399.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0075.jpg: 384x640 1 person, 376.3ms\n",
            "Speed: 2.7ms preprocess, 376.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0324.jpg: 384x640 2 persons, 6 cars, 403.4ms\n",
            "Speed: 4.1ms preprocess, 403.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0183.jpg: 384x640 (no detections), 378.8ms\n",
            "Speed: 4.2ms preprocess, 378.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0234.jpg: 384x640 1 bench, 380.3ms\n",
            "Speed: 4.8ms preprocess, 380.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0310.jpg: 384x640 1 person, 2 cars, 1 bus, 400.9ms\n",
            "Speed: 3.8ms preprocess, 400.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0125.jpg: 384x640 (no detections), 381.6ms\n",
            "Speed: 3.9ms preprocess, 381.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0180.jpg: 384x640 (no detections), 409.0ms\n",
            "Speed: 3.7ms preprocess, 409.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0082.jpg: 384x640 1 person, 2 cars, 392.8ms\n",
            "Speed: 4.1ms preprocess, 392.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0047.jpg: 384x640 (no detections), 379.5ms\n",
            "Speed: 3.6ms preprocess, 379.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0233.jpg: 384x640 1 bench, 457.7ms\n",
            "Speed: 3.1ms preprocess, 457.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0138.jpg: 384x640 (no detections), 593.6ms\n",
            "Speed: 4.0ms preprocess, 593.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0316.jpg: 384x640 1 bicycle, 7 cars, 603.8ms\n",
            "Speed: 3.8ms preprocess, 603.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0085.jpg: 384x640 1 person, 1 car, 1 motorcycle, 596.2ms\n",
            "Speed: 3.6ms preprocess, 596.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0275.jpg: 384x640 2 persons, 613.0ms\n",
            "Speed: 6.4ms preprocess, 613.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0209.jpg: 384x640 (no detections), 658.0ms\n",
            "Speed: 5.0ms preprocess, 658.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0332.jpg: 384x640 2 persons, 2 cars, 523.5ms\n",
            "Speed: 3.8ms preprocess, 523.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0012.jpg: 384x640 (no detections), 395.3ms\n",
            "Speed: 4.1ms preprocess, 395.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0230.jpg: 384x640 (no detections), 382.2ms\n",
            "Speed: 5.0ms preprocess, 382.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0248.jpg: 384x640 1 person, 1 car, 1 traffic light, 390.7ms\n",
            "Speed: 3.2ms preprocess, 390.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0042.jpg: 384x640 (no detections), 395.6ms\n",
            "Speed: 2.6ms preprocess, 395.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0100.jpg: 384x640 (no detections), 389.2ms\n",
            "Speed: 2.9ms preprocess, 389.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0241.jpg: 384x640 2 cars, 412.0ms\n",
            "Speed: 2.7ms preprocess, 412.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0314.jpg: 384x640 1 person, 4 cars, 1 bus, 387.4ms\n",
            "Speed: 5.1ms preprocess, 387.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0106.jpg: 384x640 1 car, 394.5ms\n",
            "Speed: 3.6ms preprocess, 394.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0007.jpg: 384x640 (no detections), 395.7ms\n",
            "Speed: 3.7ms preprocess, 395.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0257.jpg: 384x640 2 persons, 2 cars, 402.1ms\n",
            "Speed: 4.6ms preprocess, 402.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0111.jpg: 384x640 1 car, 402.0ms\n",
            "Speed: 4.2ms preprocess, 402.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0334.jpg: 384x640 2 persons, 1 car, 392.7ms\n",
            "Speed: 5.1ms preprocess, 392.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0121.jpg: 384x640 (no detections), 390.8ms\n",
            "Speed: 3.9ms preprocess, 390.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0043.jpg: 384x640 (no detections), 405.0ms\n",
            "Speed: 2.7ms preprocess, 405.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0132.jpg: 384x640 (no detections), 395.5ms\n",
            "Speed: 3.9ms preprocess, 395.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0192.jpg: 384x640 (no detections), 417.9ms\n",
            "Speed: 3.5ms preprocess, 417.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0157.jpg: 384x640 1 person, 3 cars, 404.7ms\n",
            "Speed: 3.9ms preprocess, 404.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0251.jpg: 384x640 1 person, 1 car, 385.8ms\n",
            "Speed: 2.6ms preprocess, 385.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0191.jpg: 384x640 (no detections), 399.3ms\n",
            "Speed: 4.9ms preprocess, 399.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0204.jpg: 384x640 (no detections), 389.6ms\n",
            "Speed: 4.2ms preprocess, 389.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0320.jpg: 384x640 5 cars, 1 truck, 407.5ms\n",
            "Speed: 4.2ms preprocess, 407.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0294.jpg: 384x640 (no detections), 395.3ms\n",
            "Speed: 3.9ms preprocess, 395.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0186.jpg: 384x640 (no detections), 386.6ms\n",
            "Speed: 3.2ms preprocess, 386.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0281.jpg: 384x640 3 cars, 482.5ms\n",
            "Speed: 4.5ms preprocess, 482.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0224.jpg: 384x640 (no detections), 606.3ms\n",
            "Speed: 7.2ms preprocess, 606.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0283.jpg: 384x640 1 car, 1 bottle, 629.5ms\n",
            "Speed: 3.9ms preprocess, 629.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0101.jpg: 384x640 (no detections), 624.8ms\n",
            "Speed: 3.8ms preprocess, 624.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0179.jpg: 384x640 1 car, 626.0ms\n",
            "Speed: 3.8ms preprocess, 626.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0175.jpg: 384x640 1 car, 664.7ms\n",
            "Speed: 3.7ms preprocess, 664.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0018.jpg: 384x640 (no detections), 525.1ms\n",
            "Speed: 4.7ms preprocess, 525.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0009.jpg: 384x640 (no detections), 413.7ms\n",
            "Speed: 5.0ms preprocess, 413.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0213.jpg: 384x640 (no detections), 385.1ms\n",
            "Speed: 5.6ms preprocess, 385.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0089.jpg: 384x640 2 persons, 1 car, 397.9ms\n",
            "Speed: 5.4ms preprocess, 397.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0307.jpg: 384x640 1 person, 385.6ms\n",
            "Speed: 3.7ms preprocess, 385.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0063.jpg: 384x640 (no detections), 383.8ms\n",
            "Speed: 3.1ms preprocess, 383.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0323.jpg: 384x640 3 persons, 5 cars, 1 truck, 396.2ms\n",
            "Speed: 4.3ms preprocess, 396.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0231.jpg: 384x640 (no detections), 389.5ms\n",
            "Speed: 4.4ms preprocess, 389.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0068.jpg: 384x640 1 person, 394.7ms\n",
            "Speed: 3.3ms preprocess, 394.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0162.jpg: 384x640 2 cars, 405.7ms\n",
            "Speed: 5.2ms preprocess, 405.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0144.jpg: 384x640 (no detections), 385.4ms\n",
            "Speed: 4.5ms preprocess, 385.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0256.jpg: 384x640 3 persons, 1 car, 396.0ms\n",
            "Speed: 4.1ms preprocess, 396.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0247.jpg: 384x640 1 car, 2 traffic lights, 405.2ms\n",
            "Speed: 5.4ms preprocess, 405.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0033.jpg: 384x640 (no detections), 410.3ms\n",
            "Speed: 3.8ms preprocess, 410.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0131.jpg: 384x640 (no detections), 402.6ms\n",
            "Speed: 5.7ms preprocess, 402.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0312.jpg: 384x640 2 persons, 6 cars, 2 buss, 391.3ms\n",
            "Speed: 4.1ms preprocess, 391.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0292.jpg: 384x640 1 bird, 393.6ms\n",
            "Speed: 4.2ms preprocess, 393.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0195.jpg: 384x640 (no detections), 391.8ms\n",
            "Speed: 3.7ms preprocess, 391.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0238.jpg: 384x640 (no detections), 396.4ms\n",
            "Speed: 2.7ms preprocess, 396.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0301.jpg: 384x640 (no detections), 399.3ms\n",
            "Speed: 3.6ms preprocess, 399.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0004.jpg: 384x640 (no detections), 380.0ms\n",
            "Speed: 4.1ms preprocess, 380.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0163.jpg: 384x640 1 person, 3 cars, 398.3ms\n",
            "Speed: 4.5ms preprocess, 398.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0208.jpg: 384x640 (no detections), 377.1ms\n",
            "Speed: 3.8ms preprocess, 377.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0184.jpg: 384x640 (no detections), 381.2ms\n",
            "Speed: 4.5ms preprocess, 381.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0327.jpg: 384x640 2 persons, 3 cars, 1 handbag, 483.8ms\n",
            "Speed: 3.7ms preprocess, 483.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0168.jpg: 384x640 2 cars, 1 truck, 590.1ms\n",
            "Speed: 7.6ms preprocess, 590.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0154.jpg: 384x640 2 cars, 622.3ms\n",
            "Speed: 5.6ms preprocess, 622.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0330.jpg: 384x640 3 persons, 1 bicycle, 3 cars, 1 backpack, 1 bottle, 1 cell phone, 634.4ms\n",
            "Speed: 6.0ms preprocess, 634.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0024.jpg: 384x640 (no detections), 604.2ms\n",
            "Speed: 6.0ms preprocess, 604.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0164.jpg: 384x640 1 person, 3 cars, 661.6ms\n",
            "Speed: 3.7ms preprocess, 661.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0287.jpg: 384x640 (no detections), 470.6ms\n",
            "Speed: 4.3ms preprocess, 470.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0189.jpg: 384x640 (no detections), 395.3ms\n",
            "Speed: 4.6ms preprocess, 395.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0270.jpg: 384x640 2 persons, 378.9ms\n",
            "Speed: 3.8ms preprocess, 378.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0010.jpg: 384x640 (no detections), 380.6ms\n",
            "Speed: 3.8ms preprocess, 380.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0199.jpg: 384x640 (no detections), 398.2ms\n",
            "Speed: 6.1ms preprocess, 398.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0118.jpg: 384x640 1 airplane, 386.7ms\n",
            "Speed: 5.7ms preprocess, 386.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0326.jpg: 384x640 3 persons, 3 cars, 1 backpack, 399.7ms\n",
            "Speed: 3.9ms preprocess, 399.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0056.jpg: 384x640 1 airplane, 374.4ms\n",
            "Speed: 4.3ms preprocess, 374.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0014.jpg: 384x640 1 train, 386.4ms\n",
            "Speed: 2.9ms preprocess, 386.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0141.jpg: 384x640 (no detections), 397.9ms\n",
            "Speed: 3.7ms preprocess, 397.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0338.jpg: 384x640 2 persons, 382.2ms\n",
            "Speed: 4.1ms preprocess, 382.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0046.jpg: 384x640 (no detections), 396.5ms\n",
            "Speed: 5.3ms preprocess, 396.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0250.jpg: 384x640 1 car, 380.9ms\n",
            "Speed: 4.1ms preprocess, 380.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0053.jpg: 384x640 1 car, 1 airplane, 388.5ms\n",
            "Speed: 3.9ms preprocess, 388.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0171.jpg: 384x640 3 cars, 389.7ms\n",
            "Speed: 3.7ms preprocess, 389.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0147.jpg: 384x640 (no detections), 378.5ms\n",
            "Speed: 4.1ms preprocess, 378.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0181.jpg: 384x640 (no detections), 418.1ms\n",
            "Speed: 3.6ms preprocess, 418.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0321.jpg: 384x640 1 person, 7 cars, 2 trucks, 387.9ms\n",
            "Speed: 3.8ms preprocess, 387.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0120.jpg: 384x640 1 person, 1 bicycle, 385.1ms\n",
            "Speed: 3.7ms preprocess, 385.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0188.jpg: 384x640 (no detections), 394.8ms\n",
            "Speed: 5.0ms preprocess, 394.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0136.jpg: 384x640 (no detections), 382.1ms\n",
            "Speed: 3.8ms preprocess, 382.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0052.jpg: 384x640 1 airplane, 395.7ms\n",
            "Speed: 5.4ms preprocess, 395.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0302.jpg: 384x640 (no detections), 390.8ms\n",
            "Speed: 4.6ms preprocess, 390.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0049.jpg: 384x640 (no detections), 390.5ms\n",
            "Speed: 3.7ms preprocess, 390.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0261.jpg: 384x640 2 persons, 427.4ms\n",
            "Speed: 3.5ms preprocess, 427.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0146.jpg: 384x640 (no detections), 595.0ms\n",
            "Speed: 3.8ms preprocess, 595.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0051.jpg: 384x640 2 cars, 1 airplane, 613.4ms\n",
            "Speed: 3.7ms preprocess, 613.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0059.jpg: 384x640 1 airplane, 592.6ms\n",
            "Speed: 4.0ms preprocess, 592.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0267.jpg: 384x640 2 persons, 606.5ms\n",
            "Speed: 6.3ms preprocess, 606.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0300.jpg: 384x640 (no detections), 618.2ms\n",
            "Speed: 3.6ms preprocess, 618.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0117.jpg: 384x640 (no detections), 579.7ms\n",
            "Speed: 3.9ms preprocess, 579.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0108.jpg: 384x640 1 truck, 377.2ms\n",
            "Speed: 4.2ms preprocess, 377.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0274.jpg: 384x640 3 persons, 401.8ms\n",
            "Speed: 4.3ms preprocess, 401.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0196.jpg: 384x640 (no detections), 385.1ms\n",
            "Speed: 4.3ms preprocess, 385.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0309.jpg: 384x640 1 car, 1 bus, 419.4ms\n",
            "Speed: 3.9ms preprocess, 419.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0268.jpg: 384x640 2 persons, 391.1ms\n",
            "Speed: 5.6ms preprocess, 391.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0159.jpg: 384x640 3 cars, 390.2ms\n",
            "Speed: 3.8ms preprocess, 390.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0296.jpg: 384x640 (no detections), 394.9ms\n",
            "Speed: 4.6ms preprocess, 394.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0239.jpg: 384x640 (no detections), 389.2ms\n",
            "Speed: 4.3ms preprocess, 389.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0244.jpg: 384x640 1 car, 397.4ms\n",
            "Speed: 4.1ms preprocess, 397.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0152.jpg: 384x640 2 cars, 376.3ms\n",
            "Speed: 3.8ms preprocess, 376.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0240.jpg: 384x640 1 car, 1 chair, 375.7ms\n",
            "Speed: 5.0ms preprocess, 375.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0134.jpg: 384x640 (no detections), 395.5ms\n",
            "Speed: 4.3ms preprocess, 395.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0315.jpg: 384x640 1 person, 6 cars, 1 truck, 384.2ms\n",
            "Speed: 4.0ms preprocess, 384.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video1.mp4_frame0083.jpg: 384x640 1 person, 2 cars, 394.5ms\n",
            "Speed: 4.6ms preprocess, 394.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0173.jpg: 384x640 2 cars, 379.0ms\n",
            "Speed: 3.6ms preprocess, 379.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/frames_dataset/video2.mp4_frame0166.jpg: 384x640 1 person, 3 cars, 386.6ms\n",
            "Speed: 4.3ms preprocess, 386.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "âœ… Generated JSON annotations for 339 frames in annotations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "076c42e8",
        "outputId": "f46f5f6b-2a21-49e4-972a-31d3ee4c0204"
      },
      "source": [
        "import os\n",
        "\n",
        "annotations_dir = 'annotations'\n",
        "json_files = [f for f in os.listdir(annotations_dir) if f.endswith('.json')]\n",
        "print(f\"Found {len(json_files)} JSON files in the '{annotations_dir}' directory.\")\n",
        "print(\"Listing first 10 JSON files:\")\n",
        "for i, file in enumerate(json_files[:10]):\n",
        "    print(file)"
      ],
      "id": "076c42e8",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 339 JSON files in the 'annotations' directory.\n",
            "Listing first 10 JSON files:\n",
            "video2.mp4_frame0305.json\n",
            "video2.mp4_frame0154.json\n",
            "video1.mp4_frame0014.json\n",
            "video1.mp4_frame0116.json\n",
            "video2.mp4_frame0161.json\n",
            "video2.mp4_frame0333.json\n",
            "video2.mp4_frame0262.json\n",
            "video1.mp4_frame0086.json\n",
            "video2.mp4_frame0218.json\n",
            "video2.mp4_frame0191.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efaf8b4a"
      },
      "source": [
        "from ultralytics import YOLO\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the YOLOv8 model globally or pass it to the function for efficiency\n",
        "# model = YOLO('yolov8s.pt')\n",
        "\n",
        "def annotate_rgb_image(image_file):\n",
        "    \"\"\"\n",
        "    Runs YOLOv8 inference on an image file object and returns annotations in a dictionary format.\n",
        "\n",
        "    Args:\n",
        "        image_file: A file-like object containing the image data (e.g., from google.colab.files.upload()).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the annotation data.\n",
        "    \"\"\"\n",
        "    # Load the model inside the function if not loaded globally\n",
        "    model = YOLO('yolov8s.pt')\n",
        "\n",
        "    # Read image data from the file object\n",
        "    image_data = image_file.read()\n",
        "    np_arr = np.frombuffer(image_data, np.uint8)\n",
        "    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error: Could not decode image.\")\n",
        "        return {}\n",
        "\n",
        "    results = model(img)  # Run inference on the image data\n",
        "\n",
        "    annotation_data = {}\n",
        "\n",
        "    for i, r in enumerate(results):\n",
        "        if r.boxes is not None:\n",
        "            annotation_data[f\"obj_{i+1}\"] = []\n",
        "            for box in r.boxes:\n",
        "                x_min, y_min, x_max, y_max = [float(coord) for coord in box.xyxy[0]]\n",
        "                confidence = float(box.conf[0])\n",
        "                class_id = int(box.cls[0])\n",
        "                obj_name = model.names[class_id]\n",
        "\n",
        "                annotation_data[f\"obj_{i+1}\"].append({\n",
        "                    \"contour\": {\"x\": x_min, \"y\": y_min, \"w\": x_max - x_min, \"h\": y_max - y_min},\n",
        "                    \"obj_name\": obj_name,\n",
        "                    \"name_accuracy\": confidence\n",
        "                })\n",
        "\n",
        "    return annotation_data\n",
        "\n",
        "# Example usage (you would replace 'path/to/your/image.jpg' with your image file)\n",
        "# image_file = 'path/to/your/image.jpg'\n",
        "# annotations = annotate_rgb_image(image_file)\n",
        "# print(json.dumps(annotations, indent=2))"
      ],
      "id": "efaf8b4a",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d15b2d0"
      },
      "source": [
        "# Task\n",
        "Download a public aerial object detection dataset, extract ~500 images and annotations, prepare data for YOLOv8, run inference using \"best.pt\", generate visual comparisons (original vs model detection), and compute evaluation metrics (mAP@0.5, mAP@0.5:0.95, precision, FPS). Save results and annotated images into folders."
      ],
      "id": "5d15b2d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d0e3e64"
      },
      "source": [
        "## Download dataset\n",
        "\n",
        "### Subtask:\n",
        "Download a public aerial object detection dataset.\n"
      ],
      "id": "0d0e3e64"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89e7e497"
      },
      "source": [
        "**Reasoning**:\n",
        "Use wget to download a publicly available aerial object detection dataset in a compressed format.\n",
        "\n"
      ],
      "id": "89e7e497"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50d923ed",
        "outputId": "071b6616-e56f-4557-da17-60f48514ee85"
      },
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v1.0/AerialMaritimeDrone.zip -O AerialMaritimeDrone.zip"
      ],
      "id": "50d923ed",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 22:52:47--  https://github.com/ultralytics/yolov5/releases/download/v1.0/AerialMaritimeDrone.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-30 22:52:47 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c85e379"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous download link resulted in a 404 error. Try downloading the dataset from a different source.\n",
        "\n"
      ],
      "id": "9c85e379"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "148597ba",
        "outputId": "cfc83605-96ad-4b4c-e12b-075392195885"
      },
      "source": [
        "!wget https://public.roboflow.com/ds/02JtZ1Xq4N?apikey=YOUR_API_KEY -O aerial_maritime_drone.zip"
      ],
      "id": "148597ba",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 22:52:51--  https://public.roboflow.com/ds/02JtZ1Xq4N?apikey=YOUR_API_KEY\n",
            "Resolving public.roboflow.com (public.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n",
            "Connecting to public.roboflow.com (public.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-30 22:52:51 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b72bef7"
      },
      "source": [
        "## Download dataset\n",
        "\n",
        "### Subtask:\n",
        "Retry downloading a public aerial object detection dataset using a different source or method.\n"
      ],
      "id": "0b72bef7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e61da5aa"
      },
      "source": [
        "**Reasoning**:\n",
        "Attempt to download a different public aerial object detection dataset using a direct download link from a reliable source. The \"VisDrone2019-DET-train\" dataset is a widely used aerial object detection dataset and the link provided is a direct download link.\n",
        "\n"
      ],
      "id": "e61da5aa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abeee674",
        "outputId": "1d549c96-5065-48dd-e488-05e625ddfeb6"
      },
      "source": [
        "!wget https://github.com/VisDrone/VisDrone2019-DET/releases/download/v2019-DET-dataset/VisDrone2019-DET-train-zip.zip -O VisDrone2019-DET-train.zip"
      ],
      "id": "abeee674",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 22:53:05--  https://github.com/VisDrone/VisDrone2019-DET/releases/download/v2019-DET-dataset/VisDrone2019-DET-train-zip.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-30 22:53:05 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41ba2be6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to download the VisDrone dataset failed. I will try another approach to download the dataset by using `gdown` with the Google Drive file ID, which is a common way to share large datasets. I'll use the file ID for the VisDrone2019-DET-train dataset found on its official website or other reliable sources.\n",
        "\n"
      ],
      "id": "41ba2be6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "b7250ec1",
        "outputId": "8d10c824-a470-4bb3-8b6a-6f335f2fc48e"
      },
      "source": [
        "!pip install gdown -q\n",
        "import gdown\n",
        "\n",
        "# Replace with the correct Google Drive file ID for VisDrone2019-DET-train\n",
        "# This ID is an example and might need to be updated with the actual ID\n",
        "file_id = '1l8g80d_0K8k3vR-vE4nB40c9iR7z3gD' # Example ID, find the correct one.\n",
        "output = 'VisDrone2019-DET-train.zip'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)"
      ],
      "id": "b7250ec1",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1l8g80d_0K8k3vR-vE4nB40c9iR7z3gD\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3941068186.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1l8g80d_0K8k3vR-vE4nB40c9iR7z3gD'\u001b[0m \u001b[0;31m# Example ID, find the correct one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'VisDrone2019-DET-train.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'https://drive.google.com/uc?id={file_id}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1l8g80d_0K8k3vR-vE4nB40c9iR7z3gD\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2ba994"
      },
      "source": [
        "**Reasoning**:\n",
        "The attempt to download the VisDrone dataset using gdown failed due to permission issues or too many accesses. I will try a different dataset source. I'll search for another publicly available aerial object detection dataset that can be downloaded directly or through a simple method. The \"Aerial Objects Detection\" dataset from Kaggle might be an alternative. Since I cannot use `wget` or `gdown` with a direct link that requires authentication or is behind a non-public sharing setting, I will try to use Kaggle's API to download the dataset.\n",
        "\n"
      ],
      "id": "fe2ba994"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19268d36",
        "outputId": "81ab1b5c-dd8f-4f1d-848e-0aad5b3faa19"
      },
      "source": [
        "import os\n",
        "\n",
        "sample_data_dir = 'sample_data'\n",
        "image_files = [f for f in os.listdir(sample_data_dir) if f.endswith('.jpg')]\n",
        "\n",
        "if image_files:\n",
        "    print(f\"Found {len(image_files)} .jpg images in '{sample_data_dir}':\")\n",
        "    for image in image_files:\n",
        "        print(image)\n",
        "else:\n",
        "    print(f\"No .jpg images found in '{sample_data_dir}'.\")"
      ],
      "id": "19268d36",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 42 .jpg images in 'sample_data':\n",
            "0000001_05249_d_0000009.jpg\n",
            "0000022_01251_d_0000007.jpg\n",
            "0000055_00714_d_0000110.jpg\n",
            "0000024_00000_d_0000012.jpg\n",
            "0000022_01036_d_0000006.jpg\n",
            "0000001_07999_d_0000012.jpg\n",
            "0000001_04527_d_0000008.jpg\n",
            "0000153_01201_d_0000001.jpg\n",
            "0000153_01801_d_0000001.jpg\n",
            "0000026_01000_d_0000026.jpg\n",
            "0000026_00500_d_0000025.jpg\n",
            "0000026_02500_d_0000029.jpg\n",
            "0000021_00000_d_0000001.jpg\n",
            "0000069_00001_d_0000001.jpg\n",
            "0000001_03499_d_0000006.jpg\n",
            "0000026_04000_d_0000032.jpg\n",
            "0000026_04500_d_0000033.jpg\n",
            "0000026_04978_d_0000034.jpg\n",
            "0000021_00500_d_0000002.jpg\n",
            "0000023_01233_d_0000011.jpg\n",
            "0000024_01000_d_0000014.jpg\n",
            "0000001_08414_d_0000013.jpg\n",
            "0000023_00000_d_0000008.jpg\n",
            "0000023_00868_d_0000010.jpg\n",
            "0000021_00800_d_0000003.jpg\n",
            "0000026_03500_d_0000031.jpg\n",
            "0000153_01601_d_0000001.jpg\n",
            "0000001_05499_d_0000010.jpg\n",
            "0000022_00000_d_0000004.jpg\n",
            "0000023_00300_d_0000009.jpg\n",
            "0000024_01543_d_0000015.jpg\n",
            "0000001_02999_d_0000005.jpg\n",
            "0000022_00500_d_0000005.jpg\n",
            "0000026_03000_d_0000030.jpg\n",
            "0000026_00000_d_0000024.jpg\n",
            "0000153_00801_d_0000001.jpg\n",
            "0000055_00000_d_0000109.jpg\n",
            "0000001_05999_d_0000011.jpg\n",
            "0000026_02000_d_0000028.jpg\n",
            "0000024_00500_d_0000013.jpg\n",
            "0000001_03999_d_0000007.jpg\n",
            "0000026_01500_d_0000027.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97be0f7",
        "outputId": "954d925c-6308-4bf2-a585-0f31f60344c2"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Assuming the annotate_rgb_image function is already defined in the environment\n",
        "\n",
        "sample_data_dir = 'sample_data'\n",
        "image_files = [f for f in os.listdir(sample_data_dir) if f.endswith('.jpg')]\n",
        "\n",
        "if image_files:\n",
        "    # Use the first found image for testing\n",
        "    test_image_path = os.path.join(sample_data_dir, image_files[0])\n",
        "    print(f\"Using '{test_image_path}' for testing the annotate_rgb_image function.\")\n",
        "\n",
        "    try:\n",
        "        # Open the image file in binary read mode\n",
        "        with open(test_image_path, 'rb') as f:\n",
        "            # Call the annotate_rgb_image function with the file object\n",
        "            annotations = annotate_rgb_image(f)\n",
        "\n",
        "        # Print the JSON output\n",
        "        print(\"\\nAnnotation JSON output:\")\n",
        "        print(json.dumps(annotations, indent=2))\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The test image file '{test_image_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during annotation: {e}\")\n",
        "else:\n",
        "    print(f\"No .jpg images found in '{sample_data_dir}' to test the function with.\")"
      ],
      "id": "d97be0f7",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 'sample_data/0000001_05249_d_0000009.jpg' for testing the annotate_rgb_image function.\n",
            "\n",
            "0: 384x640 4 persons, 29 cars, 1 bus, 2 trucks, 1 clock, 419.9ms\n",
            "Speed: 5.7ms preprocess, 419.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "Annotation JSON output:\n",
            "{\n",
            "  \"obj_1\": [\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 697.9920043945312,\n",
            "        \"y\": 961.5401000976562,\n",
            "        \"w\": 169.11639404296875,\n",
            "        \"h\": 116.13555908203125\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.8197142481803894\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 838.2745971679688,\n",
            "        \"y\": 553.629150390625,\n",
            "        \"w\": 87.501708984375,\n",
            "        \"h\": 82.2664794921875\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.7993484735488892\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 738.8843994140625,\n",
            "        \"y\": 502.4052429199219,\n",
            "        \"w\": 77.8956298828125,\n",
            "        \"h\": 75.19442749023438\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.6764042973518372\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 764.6400146484375,\n",
            "        \"y\": 404.13018798828125,\n",
            "        \"w\": 74.4678955078125,\n",
            "        \"h\": 67.98193359375\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.6538574695587158\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1.7490921020507812,\n",
            "        \"y\": 807.4822998046875,\n",
            "        \"w\": 286.6422653198242,\n",
            "        \"h\": 270.7705078125\n",
            "      },\n",
            "      \"obj_name\": \"bus\",\n",
            "      \"name_accuracy\": 0.6406591534614563\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1143.13671875,\n",
            "        \"y\": 227.97386169433594,\n",
            "        \"w\": 45.9686279296875,\n",
            "        \"h\": 47.03080749511719\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.6130065321922302\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1126.235595703125,\n",
            "        \"y\": 148.541259765625,\n",
            "        \"w\": 51.22412109375,\n",
            "        \"h\": 43.40153503417969\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.6117770671844482\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 861.3074951171875,\n",
            "        \"y\": 269.84814453125,\n",
            "        \"w\": 60.901611328125,\n",
            "        \"h\": 58.326385498046875\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.6005791425704956\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 790.6241455078125,\n",
            "        \"y\": 506.0777282714844,\n",
            "        \"w\": 94.385009765625,\n",
            "        \"h\": 85.43331909179688\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.5968239903450012\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 943.651123046875,\n",
            "        \"y\": 203.87564086914062,\n",
            "        \"w\": 54.40228271484375,\n",
            "        \"h\": 43.751220703125\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.5934358239173889\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 896.6325073242188,\n",
            "        \"y\": 194.9051513671875,\n",
            "        \"w\": 59.17437744140625,\n",
            "        \"h\": 47.28826904296875\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.5717045068740845\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 915.3198852539062,\n",
            "        \"y\": 833.029541015625,\n",
            "        \"w\": 140.33233642578125,\n",
            "        \"h\": 163.03546142578125\n",
            "      },\n",
            "      \"obj_name\": \"truck\",\n",
            "      \"name_accuracy\": 0.5453363060951233\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 670.159423828125,\n",
            "        \"y\": 502.31231689453125,\n",
            "        \"w\": 61.44287109375,\n",
            "        \"h\": 70.06622314453125\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.5407844185829163\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 931.865478515625,\n",
            "        \"y\": 976.7191772460938,\n",
            "        \"w\": 62.4232177734375,\n",
            "        \"h\": 56.10601806640625\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.5368313193321228\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 681.7220458984375,\n",
            "        \"y\": 151.0116424560547,\n",
            "        \"w\": 63.21221923828125,\n",
            "        \"h\": 43.58140563964844\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.5276899337768555\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1007.3477783203125,\n",
            "        \"y\": 206.3188934326172,\n",
            "        \"w\": 54.4229736328125,\n",
            "        \"h\": 44.349334716796875\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.49970507621765137\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 836.5578002929688,\n",
            "        \"y\": 262.5336608886719,\n",
            "        \"w\": 250.91192626953125,\n",
            "        \"h\": 263.7704162597656\n",
            "      },\n",
            "      \"obj_name\": \"truck\",\n",
            "      \"name_accuracy\": 0.48821717500686646\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 779.9088134765625,\n",
            "        \"y\": 261.2908935546875,\n",
            "        \"w\": 62.427978515625,\n",
            "        \"h\": 56.279754638671875\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.4837593734264374\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1064.021240234375,\n",
            "        \"y\": 211.70436096191406,\n",
            "        \"w\": 46.91748046875,\n",
            "        \"h\": 40.85810852050781\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.48351308703422546\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1256.7747802734375,\n",
            "        \"y\": 978.673095703125,\n",
            "        \"w\": 29.45068359375,\n",
            "        \"h\": 60.7078857421875\n",
            "      },\n",
            "      \"obj_name\": \"person\",\n",
            "      \"name_accuracy\": 0.4675462245941162\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 598.3504028320312,\n",
            "        \"y\": 140.98193359375,\n",
            "        \"w\": 63.95416259765625,\n",
            "        \"h\": 42.56849670410156\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.46514928340911865\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 475.4367370605469,\n",
            "        \"y\": 333.8962707519531,\n",
            "        \"w\": 64.91104125976562,\n",
            "        \"h\": 65.30917358398438\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.4472177028656006\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 699.069091796875,\n",
            "        \"y\": 287.53155517578125,\n",
            "        \"w\": 65.577392578125,\n",
            "        \"h\": 62.9395751953125\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.4396345913410187\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 846.5096435546875,\n",
            "        \"y\": 187.2550506591797,\n",
            "        \"w\": 50.84710693359375,\n",
            "        \"h\": 45.30999755859375\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.430292546749115\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1105.1201171875,\n",
            "        \"y\": 221.28048706054688,\n",
            "        \"w\": 41.9693603515625,\n",
            "        \"h\": 46.455322265625\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.42619937658309937\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1004.9302978515625,\n",
            "        \"y\": 980.0726318359375,\n",
            "        \"w\": 24.2528076171875,\n",
            "        \"h\": 47.6385498046875\n",
            "      },\n",
            "      \"obj_name\": \"person\",\n",
            "      \"name_accuracy\": 0.40605267882347107\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1496.366455078125,\n",
            "        \"y\": 705.1497802734375,\n",
            "        \"w\": 22.317138671875,\n",
            "        \"h\": 50.72772216796875\n",
            "      },\n",
            "      \"obj_name\": \"person\",\n",
            "      \"name_accuracy\": 0.3821371793746948\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 656.1901245117188,\n",
            "        \"y\": 287.6228942871094,\n",
            "        \"w\": 53.1142578125,\n",
            "        \"h\": 51.38616943359375\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.35155779123306274\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 445.4061584472656,\n",
            "        \"y\": 247.8189697265625,\n",
            "        \"w\": 83.62094116210938,\n",
            "        \"h\": 51.296478271484375\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.33366644382476807\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1459.0103759765625,\n",
            "        \"y\": 633.0203857421875,\n",
            "        \"w\": 35.0445556640625,\n",
            "        \"h\": 47.431640625\n",
            "      },\n",
            "      \"obj_name\": \"clock\",\n",
            "      \"name_accuracy\": 0.3285630941390991\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1024.1131591796875,\n",
            "        \"y\": 149.63804626464844,\n",
            "        \"w\": 41.6082763671875,\n",
            "        \"h\": 35.555145263671875\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.32759496569633484\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1191.0360107421875,\n",
            "        \"y\": 128.56509399414062,\n",
            "        \"w\": 38.537353515625,\n",
            "        \"h\": 38.47492980957031\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.320579469203949\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 1178.218994140625,\n",
            "        \"y\": 74.61445617675781,\n",
            "        \"w\": 54.2239990234375,\n",
            "        \"h\": 36.59349060058594\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.31927162408828735\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 602.518798828125,\n",
            "        \"y\": 269.7159118652344,\n",
            "        \"w\": 56.48876953125,\n",
            "        \"h\": 46.15631103515625\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.2958100736141205\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 534.4096069335938,\n",
            "        \"y\": 264.73626708984375,\n",
            "        \"w\": 61.7650146484375,\n",
            "        \"h\": 53.64874267578125\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.2696789503097534\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 757.5623168945312,\n",
            "        \"y\": 163.8713836669922,\n",
            "        \"w\": 57.94097900390625,\n",
            "        \"h\": 44.7777099609375\n",
            "      },\n",
            "      \"obj_name\": \"car\",\n",
            "      \"name_accuracy\": 0.25741109251976013\n",
            "    },\n",
            "    {\n",
            "      \"contour\": {\n",
            "        \"x\": 927.4011840820312,\n",
            "        \"y\": 809.60595703125,\n",
            "        \"w\": 25.94696044921875,\n",
            "        \"h\": 40.87646484375\n",
            "      },\n",
            "      \"obj_name\": \"person\",\n",
            "      \"name_accuracy\": 0.25318410992622375\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "790a85b0",
        "outputId": "008856a7-2f2d-403a-b90d-05e42bfd244a"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO # Assuming YOLO is imported in a previous cell\n",
        "import cv2 # Assuming cv2 is imported in a previous cell\n",
        "import numpy as np # Assuming numpy is imported in a previous cell\n",
        "\n",
        "# Assuming the annotate_rgb_image function is already defined in the environment\n",
        "# Assuming 'sample_data' directory exists and contains .jpg images\n",
        "\n",
        "output_test_dir = Path('annotationtestfunction work smartly')\n",
        "output_test_dir.mkdir(exist_ok=True)\n",
        "\n",
        "sample_data_dir = 'sample_data'\n",
        "image_files = [f for f in os.listdir(sample_data_dir) if f.endswith('.jpg')]\n",
        "\n",
        "if image_files:\n",
        "    # Use the first found image for testing\n",
        "    test_image_path = os.path.join(sample_data_dir, image_files[0])\n",
        "    print(f\"Using '{test_image_path}' for testing the annotate_rgb_image function and saving output.\")\n",
        "\n",
        "    try:\n",
        "        # Open the image file in binary read mode\n",
        "        with open(test_image_path, 'rb') as f:\n",
        "            # Call the annotate_rgb_image function with the file object\n",
        "            annotations = annotate_rgb_image(f)\n",
        "\n",
        "        # Define the output JSON filename\n",
        "        output_json_filename = output_test_dir / f\"{Path(test_image_path).stem}_annotation_test.json\"\n",
        "\n",
        "        # Save the JSON output to the specified directory\n",
        "        with open(output_json_filename, 'w') as f:\n",
        "            json.dump(annotations, f, indent=2)\n",
        "\n",
        "        print(f\"âœ… Annotation output saved to '{output_json_filename}'\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The test image file '{test_image_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during annotation or saving: {e}\")\n",
        "else:\n",
        "    print(f\"No .jpg images found in '{sample_data_dir}' to test the function with.\")"
      ],
      "id": "790a85b0",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 'sample_data/0000001_05249_d_0000009.jpg' for testing the annotate_rgb_image function and saving output.\n",
            "\n",
            "0: 384x640 4 persons, 29 cars, 1 bus, 2 trucks, 1 clock, 654.0ms\n",
            "Speed: 5.4ms preprocess, 654.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "âœ… Annotation output saved to 'annotationtestfunction work smartly/0000001_05249_d_0000009_annotation_test.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installer Git si ce nâ€™est pas fait\n",
        "!apt-get install git\n",
        "\n",
        "# Configurer ton nom et email Git\n",
        "!git config --global user.name \"TonNomGitHub\"\n",
        "!git config --global user.email \"ton@email.com\"\n"
      ],
      "metadata": {
        "id": "PnzrF6Dt2jIF"
      },
      "id": "PnzrF6Dt2jIF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}